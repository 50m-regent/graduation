---

marp: true
math: mathjax
style: |
  /* 三重引用を脚注の記号に転用 */
  /* 下記はdefaultテーマ用。他のテーマで利用するときはbottomとleftを調節してください。 */
  /* スライド全体で利用するため、無名のstyleタグを利用しています。 */
  blockquote > blockquote > blockquote {
    font-size: 75%;
    font-weight: 400;
    padding: 0;
    margin: 0;
    border: 0;
    border-top: 0.1em dashed #555;
    position: absolute;
    bottom: 70px;
    left: 70px;
    width: 89%
  }

---

# 位置エンコーディング周りの諸検証

### 情報数理システム分野 B4 平田蓮

---

## 目次

- 既存のモデルから位置エンコーディングを除去
  - Encoderモデル（BERT）
  - Decoderモデル（GPT-2）
- デコーダモデルにおける位置エンコーディングをAttentionマスクで代用

---

## 位置エンコーディングを除去

位置エンコーディングが実際にどれほど重要なのかを調査

2種類のモデルで調査
- Encoderモデル（BERT）: 入力シーケンスを特徴量に変換
- Decoderモデル（GPT-2）: 入力シーケンスに対して、（続く）トークンを生成

評価用のデータセットはIMDB[1]を起用。文章の2値分類データ

>>> [1] https://ai.stanford.edu/~amaas/data/sentiment

---

## BERTの位置エンコーディングを除去

BERT-baseの構造

- 入力 $\boldsymbol{x}$ - トークンのシーケンス（ $x_1, x_2, \cdots x_n$ ）
- 出力 $\boldsymbol{y}$ - トークンごとの特徴量のシーケンス（ $\boldsymbol{y}_1, \boldsymbol{y}_2, \cdots \boldsymbol{y}_n$ ）
  - 特徴量の次元は768（ $\boldsymbol{y}_i = \{y_{i, 1}, y_{i, 2}, \cdots y_{i, 768}\}$ ）
  - 特徴量は正規化される
- 埋め込み機構 - 各トークンを768次元の特徴量に変換 $\mathbb{R} \rightarrow \mathbb{R}^{768}$
  - 単語埋め込み: トークンを表す添字を768次元のベクトルに変換
  - **位置埋め込み**: 位置を表す添字を768次元のベクトルに変換
  - これらの埋め込みを加算して、Encoderに与える
- Encoder機構 - Headを12個のMulti-Head Attentionのブロックが12層 $\mathbb{R}^{768} \rightarrow \mathbb{R}^{768}$

---

## BERTの位置エンコーディングを除去

位置埋め込みの値を0にして加算しても影響がないように

- 位置埋め込みあり・なしのBERTの特徴量同士のコサイン類似度を算出
- これが高かったら位置埋め込みなしでも同様の情報を持った特徴量ができる
  - 要議論

---

## BERTの位置エンコーディングを除去

- 位置埋め込みあり・なしのモデルでテストデータに対して特徴量を生成
- 各トークンの特徴量同士のコサイン類似度を算出
- データ全体で平均を取る

##### 結果: 0.7702

---

## BERTの位置エンコーディングを除去

コサイン類似度0.7702は高いのか

- サンプリングで768次元のベクトルのコサイン類似度の分布を見てみる
- 平均が$\boldsymbol{0}$、分散共分散行列が単位行列の多次元正規分布の密度関数は、
    $$
        f(\boldsymbol{x}) = \frac{1}{Z}\exp\left(-\frac{1}{2} {}^t\boldsymbol{x}\boldsymbol{x}\right) = \frac{1}{Z}\exp\left(-\frac{1}{2} \|\boldsymbol{x}\|\right)
    $$
    なので、方向は一様にサンプリングできる

---

## BERTの位置エンコーディングを除去

コサイン類似度0.7702は高いのか - 結果

![h:400 center](images/768.png)

高そう（少なくとも位置埋め込みを抜いたらランダムになってしまうとかではない）

---

## BERTの位置エンコーディングを除去

- 低くはないコサイン類似度が得られた
- 位置埋め込みを抜いた特徴量が実際にどれくらい使えるのかは、**下流タスクのモデルを学習して評価する必要あり**

---

## GPT-2の位置エンコーディングを除去

---

## 位置エンコーディングをAttentionマスクで代用

位置エンコーディングの除去可能性を模索